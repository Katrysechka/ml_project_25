{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11999666,"sourceType":"datasetVersion","datasetId":7548378}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mteb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:51:59.840885Z","iopub.execute_input":"2025-05-29T19:51:59.841426Z","iopub.status.idle":"2025-05-29T19:53:17.885788Z","shell.execute_reply.started":"2025-05-29T19:51:59.841397Z","shell.execute_reply":"2025-05-29T19:53:17.885076Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IDX_SLERP = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\nfrom safetensors.torch import load_file, save_file\nfrom sentence_transformers import SentenceTransformer, models\nfrom transformers import AutoTokenizer\nimport mteb\nimport numpy as np\nimport math\nimport pandas as pd\nimport shutil\n\n# Configuration\nsymm_model_dir = \"/kaggle/input/s2-models-embed/epoch_1_model/epoch_1\"      # symmetric model folder\nasymm_model_dir = \"/kaggle/input/s2-models-embed/epoch_1_asym/epoch_1_asym\"     # asymmetric model folder\nblend_weight = [0.1, 0.2, 0.3, 0.4, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95][IDX_SLERP]                     # fraction for symmetric model (0..1)\noutput_merged = \"merged_model\"\n\ndef slerp_weights(state_dict1, state_dict2, alpha):\n    \"\"\"\n    Spherical linear interpolation for each weight tensor.\n    \"\"\"\n    merged = {}\n    \n    # Проверка совместимости моделей\n    if set(state_dict1.keys()) != set(state_dict2.keys()):\n        raise ValueError(\"Models have different architectures - key mismatch\")\n    \n    for k in state_dict1:\n        w1 = state_dict1[k].float()\n        w2 = state_dict2[k].float()\n        \n        # Проверка размерностей\n        if w1.shape != w2.shape:\n            print(f\"Warning: Shape mismatch for {k}: {w1.shape} vs {w2.shape}\")\n            merged[k] = w1  # Используем первую модель при несовпадении\n            continue\n            \n        # Flatten\n        v1 = w1.view(-1)\n        v2 = w2.view(-1)\n        \n        # Compute norms and dot\n        dot = torch.dot(v1, v2) / (torch.norm(v1) * torch.norm(v2) + 1e-8)\n        omega = torch.acos(torch.clamp(dot, -1.0, 1.0))\n        \n        if torch.abs(omega) < 1e-6:\n            merged_tensor = w1\n        else:\n            so = torch.sin(omega)\n            part1 = torch.sin((1 - alpha) * omega) / so\n            part2 = torch.sin(alpha * omega) / so\n            merged_flat = part1 * v1 + part2 * v2\n            merged_tensor = merged_flat.view_as(w1)\n            \n        merged[k] = merged_tensor\n    return merged\n\n# Создание выходных директорий\nos.makedirs(output_merged, exist_ok=True)\nos.makedirs(\"results\", exist_ok=True)\n\nprint(\"Loading model state dicts...\")\n# Load state dicts\nsd_symm = load_file(f\"{symm_model_dir}/model.safetensors\")\nsd_asymm = load_file(f\"{asymm_model_dir}/model.safetensors\")\n\nprint(\"Merging models with SLERP...\")\n# Merge\nalpha = blend_weight\nsd_merged = slerp_weights(sd_symm, sd_asymm, alpha)\n\nprint(\"Saving merged model...\")\n# Save merged\nsave_file(sd_merged, f\"{output_merged}/model.safetensors\")\n\n# Copy config and tokenizer files\nconfig_files = ['config.json', 'tokenizer.json', 'tokenizer_config.json', 'special_tokens_map.json']\nfor fname in config_files:\n    src = f\"{symm_model_dir}/{fname}\"\n    dst = f\"{output_merged}/{fname}\"\n    if os.path.exists(src):\n        shutil.copy(src, dst)\n        print(f\"Copied {fname}\")\n    else:\n        print(f\"Warning: {fname} not found in {symm_model_dir}\")\n\nprint(\"Building SentenceTransformer with merged weights...\")\n# Build SBERT with merged weights\ndir_merged = output_merged\ntransformer = models.Transformer(\n    model_name_or_path=dir_merged,\n    tokenizer_name_or_path=dir_merged\n)\npooling = models.Pooling(\n    transformer.get_word_embedding_dimension(),\n    pooling_mode_mean_tokens=True\n)\nbase_model = SentenceTransformer(modules=[transformer, pooling])\n\n# Правильная обертка для префиксов\nclass PrefixSentenceTransformer:\n    \"\"\"\n    Wrapper для добавления префиксов согласно обучению модели.\n    Использует search_query: для запросов и search_document: для документов.\n    \"\"\"\n    def __init__(self, base_model, query_prefix=\"search_query:\", doc_prefix=\"search_document:\"):\n        self.base_model = base_model\n        self.query_prefix = query_prefix\n        self.doc_prefix = doc_prefix\n        \n    def encode(self, sentences, **kwargs):\n        \"\"\"\n        Кодирует предложения. По умолчанию считает их документами,\n        если не указан параметр is_query=True.\n        \"\"\"\n        is_query = kwargs.pop('is_query', False)\n        \n        if isinstance(sentences, str):\n            sentences = [sentences]\n            \n        if is_query:\n            prefixed_sentences = [f\"{self.query_prefix} {sent}\" for sent in sentences]\n        else:\n            prefixed_sentences = [f\"{self.doc_prefix} {sent}\" for sent in sentences]\n            \n        return self.base_model.encode(prefixed_sentences, **kwargs)\n    \n    def encode_queries(self, queries, **kwargs):\n        \"\"\"Явно кодирует запросы.\"\"\"\n        return self.encode(queries, is_query=True, **kwargs)\n    \n    def encode_corpus(self, corpus, **kwargs):\n        \"\"\"Явно кодирует документы корпуса.\"\"\"\n        # Корпус может быть словарем с ключами 'title' и 'text'\n        if isinstance(corpus, dict) and len(corpus) > 0:\n            # Если это словарь корпуса (doc_id -> {'title': ..., 'text': ...})\n            texts = []\n            for doc_id, doc in corpus.items():\n                if isinstance(doc, dict):\n                    # Объединяем title и text если есть\n                    title = doc.get('title', '')\n                    text = doc.get('text', '')\n                    combined = f\"{title} {text}\".strip() if title else text\n                    texts.append(combined)\n                else:\n                    texts.append(str(doc))\n            return self.encode(texts, is_query=False, **kwargs)\n        else:\n            return self.encode(corpus, is_query=False, **kwargs)\n    \n    def save(self, path, **kwargs):\n        return self.base_model.save(path, **kwargs)\n    \n    def push_to_hub(self, *args, **kwargs):\n        return self.base_model.push_to_hub(*args, **kwargs)\n\n# Создание обернутой модели\nwrapped = PrefixSentenceTransformer(base_model)\n\nprint(\"Starting MTEB evaluation...\")\n# Evaluation - русские задачи\ntasks_list = [\n    'CEDRClassification', 'GeoreviewClassification',\n    'GeoreviewClusteringP2P', 'HeadlineClassification',\n    'InappropriatenessClassification', 'KinopoiskClassification', 'RUParaPhraserSTS',\n    'RuReviewsClassification','RuSTSBenchmarkSTS', 'RuSciBenchGRNTIClassification',\n    'RuSciBenchGRNTIClusteringP2P', 'RuSciBenchOECDClassification',\n    'RuSciBenchOECDClusteringP2P', 'SensitiveTopicsClassification',\n]\n\ntry:\n    tasks = mteb.get_tasks(tasks=tasks_list)\n    evaluator = mteb.MTEB(tasks=tasks)\n    results = evaluator.run(\n        wrapped,\n        output_folder=\"results/merged_model_mteb\",\n        eval_splits=[\"test\"],\n        verbosity=2,\n    )\n    \n    print(\"Evaluation completed successfully!\")\n    \n    # Collect scores\n    records = []\n    for r in results:\n        score = r.get_score()\n        if 'Clustering' in r.task_name:\n            task_type = 'Clustering'\n        elif 'STS' in r.task_name:\n            task_type = 'STS'\n        elif r.task_name in ['CEDRClassification', 'SensitiveTopicsClassification']:\n            task_type = 'MultilabelClassification'\n        else:\n            task_type = 'Classification'\n\n        \n        records.append({\n            \"task\": r.task_name,\n            \"score\": score,\n            \"type\": task_type\n        })\n        print(f\"{r.task_name}: {score:.4f}\")\n    \n    df = pd.DataFrame(records)\n    \n    # 1) Table: each task score\n    print(\"\\n=== Task Scores ===\")\n    print(df.to_string(index=False))\n    \n    # 2) Overall mean score\n    overall_mean = df['score'].mean()\n    print(f\"\\n=== Overall Mean Score ===\")\n    print(f\"Overall Mean: {overall_mean:.4f}\")\n    \n    # 3) Mean per type\n    type_means = df.groupby('type')['score'].mean().reset_index()\n    print(f\"\\n=== Scores by Task Type ===\")\n    print(type_means.to_string(index=False))\n    \n    # Save results\n    df.to_csv('results/task_scores.csv', index=False)\n    type_means.to_csv('results/type_means.csv', index=False)\n    with open('results/overall_mean.txt', 'w') as f:\n        f.write(f\"{overall_mean:.6f}\")\n    \n    print(f\"\\nResults saved to results/ folder\")\n    \nexcept Exception as e:\n    print(f\"Error during evaluation: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:53:57.857646Z","iopub.execute_input":"2025-05-29T19:53:57.858478Z","iopub.status.idle":"2025-05-29T19:57:43.397817Z","shell.execute_reply.started":"2025-05-29T19:53:57.858446Z","shell.execute_reply":"2025-05-29T19:57:43.397092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}